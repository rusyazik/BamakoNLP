{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prévision d'étiquettes sur StackOverflow avec régression logistique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cet exercice, vous apprendrez à prévoir les étiquettes attribuées aux publications de StackOverflow. Les étiquettes peuvent être multiples, alors, la classification doit être multi-étiquette."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-traitement de texte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour les tâches suivantes, vous devrez utiliser une liste de stop words. Elle peut être téléchargé à partir de *nltk*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette tâche, vous allez traiter un ensemble de données de titres d'articles de StackOverflow. Vous êtes fourni avec les données divisées en 3 ensembles : *train*, *validation* et *test*. Tous les corpus (à l'exception de *test*) contiennent les titres des publications et les étiquettes correspondantes (100 étiquettes sont disponibles). Téléchargez les corpus en utilisant *pandas* et regardez les données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    data = pd.read_csv(filename, sep='\\t')\n",
    "    data['tags'] = data['tags'].apply(literal_eval)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = read_data('data/train.tsv')\n",
    "validation = read_data('data/validation.tsv')\n",
    "test = pd.read_csv('data/test.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to draw a stacked dotplot in R?</td>\n",
       "      <td>[r]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mysql select all records where a datetime fiel...</td>\n",
       "      <td>[php, mysql]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How to terminate windows phone 8.1 app</td>\n",
       "      <td>[c#]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>get current time in a specific country via jquery</td>\n",
       "      <td>[javascript, jquery]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Configuring Tomcat to Use SSL</td>\n",
       "      <td>[java]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title                  tags\n",
       "0                How to draw a stacked dotplot in R?                   [r]\n",
       "1  mysql select all records where a datetime fiel...          [php, mysql]\n",
       "2             How to terminate windows phone 8.1 app                  [c#]\n",
       "3  get current time in a specific country via jquery  [javascript, jquery]\n",
       "4                      Configuring Tomcat to Use SSL                [java]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme vous pouvez le constater, la colonne *titre* contient les titres des publications et la colonne *tags* contient les étiquettes. On pourrait remarquer qu'un certain nombre de étiquettes pour une publication n'est pas fixe et peut être autant que nécessaire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour convenance, initialise *X_train*, *X_val*, *X_test*, *y_train*, *y_val*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train['title'].values, train['tags'].values\n",
    "X_val, y_val = validation['title'].values, validation['tags'].values\n",
    "X_test = test['title'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'une des difficultés lorsque l'on travaille avec des données crues est que celles-ci sont non structurées. Si vous utilisez les textes sans modification préparative et extrayez les tokens (jetons) simplement en divisant les titres par des espaces, vous verrez qu'il existe de nombreux tokens \"étranges\" ou inutiles comme *3.5?*. Il est donc généralement utile de préparer les données d’une manière ou d’une autre. Dans cette tâche, vous écrivez une fonction pour préparer les données de texte pour les traitements ultérieurs.\n",
    "\n",
    "**Tâche 1 (TextPrepare).** Implémentez la fonction *text_prepare* en suivant les instructions. Après cela, exécutez la fonction *test_text_prepare* pour le tester sur quelques exemples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def text_prepare(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = # texte en minuscule\n",
    "    text = # remplacer les symboles REPLACE_BY_SPACE_RE par des espaces dans le texte\n",
    "    text = # supprimer les symboles qui se trouvent dans BAD_SYMBOLS_RE du texte\n",
    "    text = # supprimer stopwords du texte\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_text_prepare():\n",
    "    examples = [\"SQL Server - any equivalent of Excel's CHOOSE function?\",\n",
    "                \"How to free c++ memory vector<int> * arr?\"\n",
    "                \"Pausing a method for set # of milliseconds\"]\n",
    "    answers = [\"sql server equivalent excels choose function\", \n",
    "               \"free c++ memory vectorint arr\"\n",
    "               \"pausing method set # milliseconds\"]\n",
    "    for ex, ans in zip(examples, answers):\n",
    "        print(text_prepare(ex))\n",
    "        if text_prepare(ex) != ans:\n",
    "            return \"Wrong answer for the case: '%s'\" % ex\n",
    "    return 'Basic tests are passed.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_text_prepare())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exécuter votre implémentation pour les questions du fichier *text_prepare_tests.tsv*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_questions = []\n",
    "for line in open('data/text_prepare_tests.tsv', encoding='utf-8'):\n",
    "    line = text_prepare(line.strip())\n",
    "    prepared_questions.append(line)\n",
    "text_prepare_results = '\\n'.join(prepared_questions)\n",
    "\n",
    "# Examinez contenu de text_prepare_results \n",
    "# 100 éléments\n",
    "######################################\n",
    "######### VOTRE CODE ICI #############\n",
    "######################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, nous allons prétraiter les titres en utilisant la fonction * text_prepare * et en nous assurant que les titres n'ont pas de mauvais symboles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [text_prepare(x) for x in X_train]\n",
    "X_val = [text_prepare(x) for x in X_val]\n",
    "X_test = [text_prepare(x) for x in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour chaque étiquette et chaque mot, calculez combien de fois qu'ils apparaissent dans le corpus *train*.\n",
    "\n",
    "**Tâche 2 (BagofWords).** Trouvez les 3 étiquettes les plus communes et les 3 mots les plus communs dans le corpus *train*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionnaire de toutes les étiquettes du corpus *train* avec leurs comptes\n",
    "tags_counts = {}\n",
    "# Dictionnaire de tous mots du *train* corpus avec leurs comptes\n",
    "words_counts = {}\n",
    "\n",
    "######################################\n",
    "######### VOTRE CODE ICI #############\n",
    "######################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*tags_counts* et *words_counts* seront des dictionnaires comme `{'un_mot_ou_étiquette': fréquence}`. Après application de la procédure de tri, les résultats seront: `[('mot_ou_étiquette_le_plus_commun', fréquence), ('mot_ou_étiquette_le_moins-commun', fréquence), ...]`. Imprimez les 3 étiquettes et les 3 mots les plus communs comme montré ci-dessous:\n",
    "\n",
    "    étiquette1,étiquette2,étiquette3\n",
    "    mot1,mot2,mot3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_tags = sorted(tags_counts.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "most_common_words = sorted(words_counts.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "\n",
    "# Imprimez toutes les 3 étiquettes et les 3 mots les plus communs.\n",
    "######################################\n",
    "######### VOTRE CODE ICI #############\n",
    "######################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer du texte aux vecteurs\n",
    "\n",
    "Les algorithmes d'apprentissage automatique fonctionnent avec des données numériques. Il existe de nombreuses façons de transformer des données texte en vecteurs numériques. Dans cette tâche, vous allez essayer d’en utiliser deux.\n",
    "\n",
    "#### Bag of words\n",
    "\n",
    "L'une des approches les plus connues est la représentation en «bag of words». Pour créer cette transformation, suivez les étapes suivantes:\n",
    "1. Trouvez *N* les mots les plus utilisés dans le corpus *train* et numérotez-les. Nous avons maintenant un dictionnaire des mots les plus communs.\n",
    "2. Pour chaque titre dans les corpus, créez un vecteur zéro dont la dimension est égale à *1xN*.\n",
    "3. Pour chaque mot dans chaque titre dans les corpus, parcourez les mots du dictionnaire et attribuez la valeur 1 à la coordonnée correspondante à l'index du mot dans le vecteur. (Vous observerez que le vecteur peut être extrêmement creuse. L'observation est significative.)\n",
    "\n",
    "Voici un exemple. Supposons que *N* = 4 et que la liste des mots les plus communs est :  \n",
    "\n",
    "    ['hi', 'you', 'me', 'are']\n",
    "\n",
    "Ensuite, nous devons les numéroter, par exemple, comme ceci:\n",
    "\n",
    "    {'hi': 0, 'you': 1, 'me': 2, 'are': 3}\n",
    "\n",
    "Maintenant, nous transformerons chaque titre en vecteur. Par exemple:\n",
    "\n",
    "    'hi how are you'\n",
    "\n",
    "Pour ce titre, nous créons un vecteur zéro\n",
    "\n",
    "    [0, 0, 0, 0]\n",
    "    \n",
    "Puis, nous parcourons tous les mots du titre, et si un mot est dans le dictionnaire, nous attribuons la valeur 1 à la coordonnée correspondante dans le vecteur:\n",
    "\n",
    "    'hi':  [1, 0, 0, 0]\n",
    "    'how': [1, 0, 0, 0] # mot 'how' ne se trouve pas dans le dictionnaire\n",
    "    'are': [1, 0, 0, 1]\n",
    "    'you': [1, 1, 0, 1]\n",
    "\n",
    "Le vecteur résultant est\n",
    "\n",
    "    [1, 1, 0, 1]\n",
    "   \n",
    "Implémentez cet algorithme dans la fonction *my_bag_of_words* avec la taille du dictionnaire égale à 5000. Pour trouver les mots les plus communs, utilisez les données de *train*. Vous pouvez tester votre code en utilisant la fonction *test_my_bag_of_words*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DICT_SIZE = 5000\n",
    "WORDS_TO_INDEX = ####### VOTRE CODE ICI #######\n",
    "\n",
    "ALL_WORDS = WORDS_TO_INDEX.keys()\n",
    "\n",
    "def my_bag_of_words(text, words_to_index, dict_size):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        dict_size: size of the dictionary\n",
    "        \n",
    "        return a vector which is a bag-of-words representation of 'text'\n",
    "    \"\"\"\n",
    "    result_vector = np.zeros(dict_size)\n",
    "    ######################################\n",
    "    ######### VOTRE CODE ICI #############\n",
    "    ######################################\n",
    "    return result_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_my_bag_of_words():\n",
    "    words_to_index = {'hi': 0, 'you': 1, 'me': 2, 'are': 3}\n",
    "    examples = ['hi how are you']\n",
    "    answers = [[1, 1, 0, 1]]\n",
    "    for ex, ans in zip(examples, answers):\n",
    "        if (my_bag_of_words(ex, words_to_index, 4) != ans).any():\n",
    "            return \"Wrong answer for the case: '%s'\" % ex\n",
    "    return 'Basic tests are passed.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_my_bag_of_words())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appliquez maintenant la fonction implémentée à tous les trois corpus *train*, *validate* et *test* (le calcul exigera du temps). Nous transformons les données en vecteurs creuses afin de stocker efficacement les informations utiles. Il existe de nombreux types de telles représentations [types](https://docs.scipy.org/doc/scipy/reference/sparse.html) , mais les algorithmes sklearn ne peuvent fonctionner qu'avec la matrice csr, nous allons donc utiliser celle-ci. [csr](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html#scipy.sparse.csr_matrix) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse as sp_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X_train])\n",
    "X_val_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X_val])\n",
    "X_test_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X_test])\n",
    "print('X_train shape ', X_train_mybag.shape)\n",
    "print('X_val shape ', X_val_mybag.shape)\n",
    "print('X_test shape ', X_test_mybag.shape)\n",
    "X_train_mybag.toarray()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tâche 3 (BagOfWords, Matrice Creuse).** Pour la 11ème ligne de *X_train_mybag*, imprimez le nombre d'éléments non nuls dont il dispose. Dans cette tâche, la réponse (variable *non_zero_elements_count*) doit être un nombre, par exemple, 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = X_train_mybag[10].toarray()[0]\n",
    "non_zero_elements_count = ####### YOUR CODE HERE #######\n",
    "\n",
    "######################################\n",
    "######### VOTRE CODE ICI #############\n",
    "######################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF\n",
    "\n",
    "La deuxième approche essaye d'améliorer du bag-of-words en tenant compte de la fréquence totale des mots dans les corpus. Il pourrait être utile à pénaliser les mots trop fréquents afin de rendre l'espace de features plus percutant.\n",
    "\n",
    "Implémentez la fonction *tfidf_features* en utilisant la classe TfidfVectorizer de scikit-learn. [TfidfVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) Utilisez le corpus *train* pour pour l'entrainement du vectoriseur. N'oubliez pas d'examiner les arguments que vous pouvez lui transmettre. Nous vous suggérons de filtrer les mots trop rares (moins de 5 titres) et trop fréquents (plus de 90% des titres). En outre, utilisez des bigrammes avec des unigrammes dans votre vocabulaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_features(X_train, X_val, X_test):\n",
    "    \"\"\"\n",
    "        X_train, X_val, X_test — samples        \n",
    "        return TF-IDF vectorized representation of each sample and vocabulary\n",
    "    \"\"\"\n",
    "    # Créer un vectoriseur TF-IDF avec un choix de paramètres approprié\n",
    "    # Fit le vectoriseur sur le corpus train.\n",
    "    # Transformez les train, test, and validation données et donnez les résultats \n",
    "    #    (attention de ne pas fit le corpus train deux fois)\n",
    "    \n",
    "    tfidf_vectorizer = ####### VOTRE CODE ICI #######\n",
    "    \n",
    "    ######################################\n",
    "    ######### VOTRE CODE ICI #############\n",
    "    ######################################\n",
    "    \n",
    "    return vecs_X_train, vecs_X_val, vecs_X_test, tfidf_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois le pré-traitement du texte terminé, examinez toujours les résultats. Soyez très prudent à cette étape, car les performances des futurs modèles en dépendront énormément.\n",
    "\n",
    "Vérifiez si vous avez c ++ ou c # dans votre vocabulaire, car il s’agit bien d'étiquettes importants dans notre tâche de prédiction :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf, X_val_tfidf, X_test_tfidf, tfidf_vocab = tfidf_features(X_train, X_val, X_test)\n",
    "print (X_train_tfidf.shape)\n",
    "print (X_val_tfidf.shape)\n",
    "print (X_test_tfidf.shape)\n",
    "tfidf_reversed_vocab = {i:word for word,i in tfidf_vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### VOTRE CODE ICI #############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si vous ne pouvez pas les trouver, nous devons comprendre comment il s'est produit de les perdre. Cela s'est produit lors de la génération de étiquettes intégrée de TfidfVectorizer. Heureusement, nous pouvons influencer ce processus. Revenez à la fonction ci-dessus et utilisez le RegEx '(\\S+)' en tant que *token_pattern* dans le constructeur du vectoriseur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, utilisez cette transformation pour les données et vérifiez à nouveau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### VOTRE CODE ICI #############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificateur MultiLabel\n",
    "\n",
    "Chaque titre peut comporter plusieurs étiquettes. Pour traiter ce type de prédiction, nous devons transformer les étiquettes en une forme binaire et la prédiction sera un masque de 0 et de 1. À cette fin, il est commode d'utiliser [MultiLabelBinarizer] (http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html) de *sklearn*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['tags'].values\n",
    "y_val = validation['tags'].values\n",
    "mlb = MultiLabelBinarizer(classes=sorted(tags_counts.keys()))\n",
    "y_train = mlb.fit_transform(y_train)\n",
    "y_val = mlb.fit_transform(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implémentez la fonction *train_classifier* pour effectuer l'entraînement d'un classificateur. Dans cette tâche, utilisez l'approche One-vs-Rest, implémentée dans la classe OneVsRestClassifier [OneVsRestClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsRestClassifier.html). Dans cette approche, *k* classificateurs (k = nombre d'étiquettes) sont entraînés. Vous devez choisir un classificateur de base qui sera executé par OneVsRestClassifier. LogisticRegression [LogisticRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) est l'une des méthodes les plus simples, mais elle est souvent assez performante pour les tâches de la classification de texte. Cela peut prendre un certain temps, car le nombre de classificateurs est important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(X_train, y_train):\n",
    "    \"\"\"\n",
    "      X_train, y_train — training data\n",
    "      \n",
    "      return: trained classifier\n",
    "    \"\"\"\n",
    "    \n",
    "    # Créez et fit la régression logistique intégrée à OneVsRestClassifier.\n",
    "\n",
    "    ######################################\n",
    "    ######### Votre code ici #############\n",
    "    ######################################    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entraînez les classificateurs pour les deux différentes transformations de données: *bag-of-words* et *tf-idf*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_mybag = train_classifier(X_train_mybag, y_train)\n",
    "classifier_tfidf = train_classifier(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez maintenant créer des prévisions pour les données. Vous aurez deux types de données sortantes : les étiquettes prédites et les scores donnant le taux de confiance dans la prévision. Les classifications sont éffectués sur le corpus *validation* afin de nous permettre de comparer les prévisions avec les classifications réels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_predicted_labels_mybag = classifier_mybag.predict(X_val_mybag)\n",
    "y_val_predicted_scores_mybag = classifier_mybag.decision_function(X_val_mybag)\n",
    "\n",
    "y_val_predicted_labels_tfidf = classifier_tfidf.predict(X_val_tfidf)\n",
    "y_val_predicted_scores_tfidf = classifier_tfidf.decision_function(X_val_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voyons maintenant comment le classificateur TF-IDF fonctionne pour quelques exemples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred_inversed = mlb.inverse_transform(y_val_predicted_labels_tfidf)\n",
    "y_val_inversed = mlb.inverse_transform(y_val)\n",
    "for i in range(3):\n",
    "    print('Title:\\t{}\\nTrue labels:\\t{}\\nPredicted labels:\\t{}\\n\\n'.format(\n",
    "        X_val[i],\n",
    "        ','.join(y_val_inversed[i]),\n",
    "        ','.join(y_val_pred_inversed[i])\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons comparer les résultats de différentes prédictions pour voir si la transformation TF-IDF améliore les résultats en comparaison avec le bag-of-words simple ou pour essayer différentes techniques de régularisation dans la régression logistique. Pour toutes ces expériences, nous devons configurer une procédure d'évaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "Pour évaluer les résultats, nous utiliserons plusieurs mesures de classification:\n",
    " - [Accuracy](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)\n",
    " - [F1-score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html)\n",
    " - [Area under ROC-curve](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html)\n",
    " - [Area under precision-recall curve](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html#sklearn.metrics.average_precision_score) \n",
    "\n",
    "Essayez les mesures F1-score et average-précision avec les options de l'établissement de moyenne (averaging) *micro*, *macro*, et *weighted*.\n",
    "\n",
    "*micro* : Calculez les mesures globalement en comptant le total des vrais positifs, des faux négatifs et des faux positifs.\n",
    "\n",
    "*macro* : Calculez les métriques pour chaque étiquette et trouvez leur moyenne non pondérée. Cela ne prend pas en compte le déséquilibre en nombre des étiquettes.\n",
    "\n",
    "*weighted* : Calculez les métriques pour chaque étiquette et trouvez leur moyenne pondérée par support (le nombre d'instances vraies pour chaque étiquette). Cela modifie la «macro» pour tenir compte du déséquilibre des étiquettes; il peut en résulter un score F qui ne se situe pas entre precison et recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score \n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implémentez la fonction *print_evaluation_scores* qui effectue le calcule et l'affiche sur stdout:\n",
    "\n",
    " - *accuracy*\n",
    " - *F1-score macro/micro/weighted*\n",
    " - *Precision macro/micro/weighted*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_evaluation_scores(y_val, predicted):\n",
    "    \n",
    "    ######################################\n",
    "    ######### VOTRE CODE ICI #############\n",
    "    ######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Bag-of-words')\n",
    "print_evaluation_scores(y_val, y_val_predicted_labels_mybag)\n",
    "print('Tfidf')\n",
    "print_evaluation_scores(y_val, y_val_predicted_labels_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tracez une généralisation de la [ROC curve] (http://scikit-learn.org/stable/modules/model_evaluation.html#receiver-operating-characteristic-roc) pour le cas d'une classification multi-étiquettes avec la fonction fournie *roc_auc*. Les paramètres d'entrée de cette fonction sont:\n",
    " - true labels (étiquettes vraies)\n",
    " - decision functions scores (scores de la fonction de décision)\n",
    " - number of classes (nombre de volets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import roc_auc\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(tags_counts)\n",
    "roc_auc(y_val, y_val_predicted_scores_mybag, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(tags_counts)\n",
    "roc_auc(y_val, y_val_predicted_scores_tfidf, n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tâche 4 (MultilabelClassification).** \n",
    "Faites les expériences avec l'entraînement de vos classificateurs. Utiliser *F1-score weighted* comme métrique d'évaluation. \n",
    "- comparez la qualité des approches du bag-of-words et de la TF-IDF et choisissez l'une d'entre elles.\n",
    "- pour celui que vous avez choisi, essayez *L1* et *L2* régularisation en la régression logistique avec des coefficients différents (par exemple, C égal à 0,1, 1, 10, 100).\n",
    "\n",
    "Vous pouvez également essayer d'autres améliorations du pré-traitement / modèle, si vous le souhaitez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "######### VOTRE CODE ICI #############\n",
    "######################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lorsque vous êtes satisfait de la qualité, créez des prévisions pour corpus *test*. Imprimez les résultats (20000 éléments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = ######### VOTRE CODE ICI #############\n",
    "test_pred_inversed = mlb.inverse_transform(test_predictions)\n",
    "\n",
    "test_predictions_for_review = '\\n'.join('%i\\t%s' % (i, ','.join(row)) for i, row in enumerate(test_pred_inversed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse des features les plus importants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examinez les features (mots ou n-grammes) utilisées avec les poids les plus importants dans votre modèle de régression logistique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implémentez la fonction *print_words_for_tag* pour trouver les 5 features (mots) avec les poids les plus importants et les poids les moins importants pour les étiquettes *c*, *c++* et *linux*. (Vous pouvez ajoutes des autres.) Revenez à la documentation de Sklearn sur [OneVsRestClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsRestClassifier.html) et [LogisticRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) si vous en avez besoin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_words_for_tag(classifier, tag, tags_classes, index_to_words):\n",
    "    \"\"\"\n",
    "        classifier: trained classifier\n",
    "        tag: particular tag\n",
    "        tags_classes: a list of classes names from MultiLabelBinarizer\n",
    "        index_to_words: index_to_words transformation\n",
    "        \n",
    "        return nothing, just print top 5 positive and top 5 negative words for current tag\n",
    "    \"\"\"\n",
    "    print('Tag:\\t{}'.format(tag))\n",
    "    \n",
    "    # Extraire un estimateur du classificateur pour l'étiquette donnée.\n",
    "    # Extraire les coefficients des features de l'estimateur.\n",
    "    \n",
    "    ######################################\n",
    "    ######### VOTRE CODE ICI #############\n",
    "    ######################################\n",
    "    \n",
    "    top_positive_words = # top-5 mots triés par les coefficients.\n",
    "    top_negative_words = # les 5 derniers mots triés par les coefficients.\n",
    "    print('Top positive words:\\t{}'.format(', '.join(top_positive_words)))\n",
    "    print('Top negative words:\\t{}\\n'.format(', '.join(top_negative_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_words_for_tag(classifier_tfidf, 'c', mlb.classes, tfidf_reversed_vocab)\n",
    "print_words_for_tag(classifier_tfidf, 'c++', mlb.classes, tfidf_reversed_vocab)\n",
    "print_words_for_tag(classifier_tfidf, 'linux', mlb.classes, tfidf_reversed_vocab)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
